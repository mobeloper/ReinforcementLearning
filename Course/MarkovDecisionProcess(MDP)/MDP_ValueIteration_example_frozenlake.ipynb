{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af632cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "\n",
    "# Create the FrozenLake environment (default: 4x4 grid, slippery surface)\n",
    "env = gym.make(\"FrozenLake-v1\", map_name=\"8x8\", is_slippery=True, render_mode='human')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be7b2bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "gamma = 0.99            # Discount factor\n",
    "theta = 1e-8            # Convergence threshold\n",
    "max_iterations = 1000   # Optional iteration limit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de5d2de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(env, gamma=0.99, theta=1e-8):\n",
    "    \"\"\"\n",
    "    Perform value iteration to compute the optimal state-value function.\n",
    "    \"\"\"\n",
    "    value_table = np.zeros(env.observation_space.n)\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        delta = 0\n",
    "\n",
    "        for state in range(env.observation_space.n):\n",
    "            old_value = value_table[state]\n",
    "\n",
    "            action_values = []\n",
    "            for action in range(env.action_space.n):\n",
    "                value = 0\n",
    "                for prob, next_state, reward, done in env.unwrapped.P[state][action]:\n",
    "                    value += prob * (reward + gamma * value_table[next_state] * (not done))\n",
    "                action_values.append(value)\n",
    "\n",
    "            value_table[state] = max(action_values)\n",
    "            delta = max(delta, abs(old_value - value_table[state]))\n",
    "\n",
    "        if delta < theta:\n",
    "            print(f\"Converged in {i+1} iterations.\")\n",
    "            break\n",
    "\n",
    "    return value_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d5fd395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_policy(env, value_table, gamma=0.99):\n",
    "    \"\"\"\n",
    "    Derive the optimal policy from the value function.\n",
    "    \"\"\"\n",
    "    policy = np.zeros(env.observation_space.n, dtype=int)\n",
    "\n",
    "    for state in range(env.observation_space.n):\n",
    "        action_values = []\n",
    "\n",
    "        for action in range(env.action_space.n):\n",
    "            value = 0\n",
    "            for prob, next_state, reward, done in env.unwrapped.P[state][action]:\n",
    "                value += prob * (reward + gamma * value_table[next_state] * (not done))\n",
    "            action_values.append(value)\n",
    "\n",
    "        policy[state] = np.argmax(action_values)\n",
    "\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "979b3610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged in 347 iterations.\n"
     ]
    }
   ],
   "source": [
    "# Run value iteration and extract optimal policy\n",
    "optimal_value_table = value_iteration(env, gamma, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0953da31",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_policy = extract_policy(env, optimal_value_table, gamma)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4896b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal Value Function:\n",
      "[[0.41464029 0.42720516 0.44614817 0.46832032 0.49244367 0.51656979\n",
      "  0.53526148 0.54097518]\n",
      " [0.41168636 0.42120777 0.43749567 0.45838851 0.48324009 0.51353174\n",
      "  0.54576783 0.55736838]\n",
      " [0.39675202 0.39384048 0.37549622 0.         0.42167796 0.49381917\n",
      "  0.56121205 0.58585888]\n",
      " [0.36927222 0.35298248 0.30653119 0.20040369 0.30075272 0.\n",
      "  0.56901586 0.62825901]\n",
      " [0.33266384 0.2913753  0.19730914 0.         0.28929024 0.36195179\n",
      "  0.53481943 0.6896973 ]\n",
      " [0.30613619 0.         0.         0.08627638 0.21393258 0.27271393\n",
      "  0.         0.77203551]\n",
      " [0.28888542 0.         0.05769637 0.04751101 0.         0.25052147\n",
      "  0.         0.87776873]\n",
      " [0.28038877 0.20081497 0.12732648 0.         0.23959086 0.48644205\n",
      "  0.7371033  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "print(\"\\nOptimal Value Function:\")\n",
    "print(optimal_value_table.reshape((8,8)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79fc968e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal Policy (0=Left, 1=Down, 2=Right, 3=Up):\n",
      "[[3 2 2 2 2 2 2 2]\n",
      " [3 3 3 3 3 2 2 1]\n",
      " [3 3 0 0 2 3 2 1]\n",
      " [3 3 3 1 0 0 2 2]\n",
      " [0 3 0 0 2 1 3 2]\n",
      " [0 0 0 1 3 0 0 2]\n",
      " [0 0 1 0 0 0 0 2]\n",
      " [0 1 0 0 1 2 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOptimal Policy (0=Left, 1=Down, 2=Right, 3=Up):\")\n",
    "print(optimal_policy.reshape((8,8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cce2bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For Colab\n",
    "\n",
    "# def run_policy(env, policy, episodes=3):\n",
    "#     \"\"\"\n",
    "#     Simulates the given policy in the FrozenLake environment.\n",
    "#     Uses text rendering (ANSI) for each step.\n",
    "#     \"\"\"\n",
    "#     # Re-create the environment with rendering enabled\n",
    "#     env = gym.make(\"FrozenLake-v1\", is_slippery=True, render_mode=\"ansi\", map_name=\"8x8\")\n",
    "\n",
    "#     for ep in range(episodes):\n",
    "#         state, info = env.reset()\n",
    "#         done = False\n",
    "#         total_reward = 0\n",
    "#         steps = 0\n",
    "\n",
    "#         print(f\"\\n--- Episode {ep + 1} ---\")\n",
    "\n",
    "#         while not done:\n",
    "#             action = policy[state]\n",
    "#             next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "#             done = terminated or truncated\n",
    "#             total_reward += reward\n",
    "#             steps += 1\n",
    "\n",
    "#             # Render text output of the environment after each action\n",
    "#             print(env.render())\n",
    "\n",
    "#             state = next_state\n",
    "\n",
    "#         print(f\"Episode finished in {steps} steps with reward: {total_reward}\")\n",
    "\n",
    "\n",
    "# # Simulate the optimal policy\n",
    "# run_policy(env, optimal_policy, episodes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb68b5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oysterable/delete/ReinforcementLearning/rlvenv/lib/python3.12/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Episode 1 ---\n",
      "\n",
      " Episode 1: Step 1\n",
      "\n",
      " Episode 1: Step 2\n",
      "\n",
      " Episode 1: Step 3\n",
      "\n",
      " Episode 1: Step 4\n",
      "\n",
      " Episode 1: Step 5\n",
      "\n",
      " Episode 1: Step 6\n",
      "\n",
      " Episode 1: Step 7\n",
      "\n",
      " Episode 1: Step 8\n",
      "\n",
      " Episode 1: Step 9\n",
      "\n",
      " Episode 1: Step 10\n",
      "\n",
      " Episode 1: Step 11\n",
      "\n",
      " Episode 1: Step 12\n",
      "\n",
      " Episode 1: Step 13\n",
      "\n",
      " Episode 1: Step 14\n",
      "\n",
      " Episode 1: Step 15\n",
      "\n",
      " Episode 1: Step 16\n",
      "\n",
      " Episode 1: Step 17\n",
      "\n",
      " Episode 1: Step 18\n",
      "\n",
      " Episode 1: Step 19\n",
      "\n",
      " Episode 1: Step 20\n",
      "\n",
      " Episode 1: Step 21\n",
      "\n",
      " Episode 1: Step 22\n",
      "\n",
      " Episode 1: Step 23\n",
      "\n",
      " Episode 1: Step 24\n",
      "\n",
      " Episode 1: Step 25\n",
      "\n",
      " Episode 1: Step 26\n",
      "\n",
      " Episode 1: Step 27\n",
      "\n",
      " Episode 1: Step 28\n",
      "\n",
      " Episode 1: Step 29\n",
      "\n",
      " Episode 1: Step 30\n",
      "\n",
      " Episode 1: Step 31\n",
      "\n",
      " Episode 1: Step 32\n",
      "\n",
      " Episode 1: Step 33\n",
      "\n",
      " Episode 1: Step 34\n",
      "\n",
      " Episode 1: Step 35\n",
      "\n",
      " Episode 1: Step 36\n",
      "\n",
      " Episode 1: Step 37\n",
      "\n",
      " Episode 1: Step 38\n",
      "\n",
      " Episode 1: Step 39\n",
      "\n",
      " Episode 1: Step 40\n",
      "\n",
      " Episode 1: Step 41\n",
      "\n",
      " Episode 1: Step 42\n",
      "\n",
      " Episode 1: Step 43\n",
      "\n",
      " Episode 1: Step 44\n",
      "\n",
      " Episode 1: Step 45\n",
      "\n",
      " Episode 1: Step 46\n",
      "\n",
      " Episode 1: Step 47\n",
      "\n",
      " Episode 1: Step 48\n",
      "\n",
      " Episode 1: Step 49\n",
      "\n",
      " Episode 1: Step 50\n",
      "\n",
      " Episode 1: Step 51\n",
      "\n",
      " Episode 1: Step 52\n",
      "\n",
      " Episode 1: Step 53\n",
      "\n",
      " Episode 1: Step 54\n",
      "\n",
      " Episode 1: Step 55\n",
      "\n",
      " Episode 1: Step 56\n",
      "\n",
      " Episode 1: Step 57\n",
      "\n",
      " Episode 1: Step 58\n",
      "\n",
      " Episode 1: Step 59\n",
      "\n",
      " Episode 1: Step 60\n",
      "\n",
      " Episode 1: Step 61\n",
      "\n",
      " Episode 1: Step 62\n",
      "\n",
      " Episode 1: Step 63\n",
      "\n",
      " Episode 1: Step 64\n",
      "\n",
      " Episode 1: Step 65\n",
      "\n",
      " Episode 1: Step 66\n",
      "\n",
      " Episode 1: Step 67\n",
      "\n",
      " Episode 1: Step 68\n",
      "\n",
      " Episode 1: Step 69\n",
      "\n",
      " Episode 1: Step 70\n",
      "\n",
      " Episode 1: Step 71\n",
      "\n",
      " Episode 1: Step 72\n",
      "You Won!!!\n",
      "Episode 1 ended with reward: 1.0\n",
      "GAME OVER --- Terminated!!!\n",
      "Episode 1 ended with reward: 1.0\n",
      "Episode finished in 72 steps with reward: 1.0\n",
      "\n",
      "--- Episode 2 ---\n",
      "\n",
      " Episode 2: Step 1\n",
      "\n",
      " Episode 2: Step 2\n",
      "\n",
      " Episode 2: Step 3\n",
      "\n",
      " Episode 2: Step 4\n",
      "\n",
      " Episode 2: Step 5\n",
      "\n",
      " Episode 2: Step 6\n",
      "\n",
      " Episode 2: Step 7\n",
      "\n",
      " Episode 2: Step 8\n",
      "\n",
      " Episode 2: Step 9\n",
      "\n",
      " Episode 2: Step 10\n",
      "\n",
      " Episode 2: Step 11\n",
      "\n",
      " Episode 2: Step 12\n",
      "\n",
      " Episode 2: Step 13\n",
      "\n",
      " Episode 2: Step 14\n",
      "\n",
      " Episode 2: Step 15\n",
      "\n",
      " Episode 2: Step 16\n",
      "\n",
      " Episode 2: Step 17\n",
      "\n",
      " Episode 2: Step 18\n",
      "\n",
      " Episode 2: Step 19\n",
      "\n",
      " Episode 2: Step 20\n",
      "\n",
      " Episode 2: Step 21\n",
      "\n",
      " Episode 2: Step 22\n",
      "\n",
      " Episode 2: Step 23\n",
      "\n",
      " Episode 2: Step 24\n",
      "\n",
      " Episode 2: Step 25\n",
      "\n",
      " Episode 2: Step 26\n",
      "\n",
      " Episode 2: Step 27\n",
      "\n",
      " Episode 2: Step 28\n",
      "\n",
      " Episode 2: Step 29\n",
      "\n",
      " Episode 2: Step 30\n",
      "\n",
      " Episode 2: Step 31\n",
      "\n",
      " Episode 2: Step 32\n",
      "\n",
      " Episode 2: Step 33\n",
      "\n",
      " Episode 2: Step 34\n",
      "\n",
      " Episode 2: Step 35\n",
      "\n",
      " Episode 2: Step 36\n",
      "\n",
      " Episode 2: Step 37\n",
      "\n",
      " Episode 2: Step 38\n",
      "\n",
      " Episode 2: Step 39\n",
      "\n",
      " Episode 2: Step 40\n",
      "\n",
      " Episode 2: Step 41\n",
      "\n",
      " Episode 2: Step 42\n",
      "\n",
      " Episode 2: Step 43\n",
      "\n",
      " Episode 2: Step 44\n",
      "\n",
      " Episode 2: Step 45\n",
      "\n",
      " Episode 2: Step 46\n",
      "\n",
      " Episode 2: Step 47\n",
      "\n",
      " Episode 2: Step 48\n",
      "You Won!!!\n",
      "Episode 2 ended with reward: 1.0\n",
      "GAME OVER --- Terminated!!!\n",
      "Episode 2 ended with reward: 1.0\n",
      "Episode finished in 48 steps with reward: 1.0\n",
      "\n",
      "--- Episode 3 ---\n",
      "\n",
      " Episode 3: Step 1\n",
      "\n",
      " Episode 3: Step 2\n",
      "\n",
      " Episode 3: Step 3\n",
      "\n",
      " Episode 3: Step 4\n",
      "\n",
      " Episode 3: Step 5\n",
      "\n",
      " Episode 3: Step 6\n",
      "\n",
      " Episode 3: Step 7\n",
      "\n",
      " Episode 3: Step 8\n",
      "\n",
      " Episode 3: Step 9\n",
      "\n",
      " Episode 3: Step 10\n",
      "\n",
      " Episode 3: Step 11\n",
      "\n",
      " Episode 3: Step 12\n",
      "\n",
      " Episode 3: Step 13\n",
      "\n",
      " Episode 3: Step 14\n",
      "\n",
      " Episode 3: Step 15\n",
      "\n",
      " Episode 3: Step 16\n",
      "\n",
      " Episode 3: Step 17\n",
      "\n",
      " Episode 3: Step 18\n",
      "\n",
      " Episode 3: Step 19\n",
      "\n",
      " Episode 3: Step 20\n",
      "\n",
      " Episode 3: Step 21\n",
      "\n",
      " Episode 3: Step 22\n",
      "\n",
      " Episode 3: Step 23\n",
      "\n",
      " Episode 3: Step 24\n",
      "\n",
      " Episode 3: Step 25\n",
      "\n",
      " Episode 3: Step 26\n",
      "\n",
      " Episode 3: Step 27\n",
      "\n",
      " Episode 3: Step 28\n",
      "\n",
      " Episode 3: Step 29\n",
      "\n",
      " Episode 3: Step 30\n",
      "\n",
      " Episode 3: Step 31\n",
      "\n",
      " Episode 3: Step 32\n",
      "\n",
      " Episode 3: Step 33\n",
      "\n",
      " Episode 3: Step 34\n",
      "\n",
      " Episode 3: Step 35\n",
      "\n",
      " Episode 3: Step 36\n",
      "\n",
      " Episode 3: Step 37\n",
      "\n",
      " Episode 3: Step 38\n",
      "\n",
      " Episode 3: Step 39\n",
      "\n",
      " Episode 3: Step 40\n",
      "\n",
      " Episode 3: Step 41\n",
      "\n",
      " Episode 3: Step 42\n",
      "\n",
      " Episode 3: Step 43\n",
      "\n",
      " Episode 3: Step 44\n",
      "\n",
      " Episode 3: Step 45\n",
      "\n",
      " Episode 3: Step 46\n",
      "\n",
      " Episode 3: Step 47\n",
      "\n",
      " Episode 3: Step 48\n",
      "\n",
      " Episode 3: Step 49\n",
      "\n",
      " Episode 3: Step 50\n",
      "\n",
      " Episode 3: Step 51\n",
      "\n",
      " Episode 3: Step 52\n",
      "\n",
      " Episode 3: Step 53\n",
      "\n",
      " Episode 3: Step 54\n",
      "\n",
      " Episode 3: Step 55\n",
      "\n",
      " Episode 3: Step 56\n",
      "\n",
      " Episode 3: Step 57\n",
      "\n",
      " Episode 3: Step 58\n",
      "\n",
      " Episode 3: Step 59\n",
      "\n",
      " Episode 3: Step 60\n",
      "\n",
      " Episode 3: Step 61\n",
      "\n",
      " Episode 3: Step 62\n",
      "\n",
      " Episode 3: Step 63\n",
      "\n",
      " Episode 3: Step 64\n",
      "\n",
      " Episode 3: Step 65\n",
      "\n",
      " Episode 3: Step 66\n",
      "\n",
      " Episode 3: Step 67\n",
      "\n",
      " Episode 3: Step 68\n",
      "\n",
      " Episode 3: Step 69\n",
      "\n",
      " Episode 3: Step 70\n",
      "\n",
      " Episode 3: Step 71\n",
      "\n",
      " Episode 3: Step 72\n",
      "\n",
      " Episode 3: Step 73\n",
      "\n",
      " Episode 3: Step 74\n",
      "\n",
      " Episode 3: Step 75\n",
      "\n",
      " Episode 3: Step 76\n",
      "\n",
      " Episode 3: Step 77\n",
      "\n",
      " Episode 3: Step 78\n",
      "\n",
      " Episode 3: Step 79\n",
      "\n",
      " Episode 3: Step 80\n",
      "\n",
      " Episode 3: Step 81\n",
      "\n",
      " Episode 3: Step 82\n",
      "\n",
      " Episode 3: Step 83\n",
      "\n",
      " Episode 3: Step 84\n",
      "\n",
      " Episode 3: Step 85\n",
      "\n",
      " Episode 3: Step 86\n",
      "\n",
      " Episode 3: Step 87\n",
      "\n",
      " Episode 3: Step 88\n",
      "\n",
      " Episode 3: Step 89\n",
      "\n",
      " Episode 3: Step 90\n",
      "\n",
      " Episode 3: Step 91\n",
      "\n",
      " Episode 3: Step 92\n",
      "\n",
      " Episode 3: Step 93\n",
      "\n",
      " Episode 3: Step 94\n",
      "\n",
      " Episode 3: Step 95\n",
      "\n",
      " Episode 3: Step 96\n",
      "\n",
      " Episode 3: Step 97\n",
      "\n",
      " Episode 3: Step 98\n",
      "\n",
      " Episode 3: Step 99\n",
      "You Won!!!\n",
      "Episode 3 ended with reward: 1.0\n",
      "GAME OVER --- Terminated!!!\n",
      "Episode 3 ended with reward: 1.0\n",
      "Episode finished in 99 steps with reward: 1.0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def run_policy(env, policy, episodes=3, delay=0.5):\n",
    "    \"\"\"\n",
    "    Simulates the given policy in the FrozenLake environment.\n",
    "    Uses graphical rendering (render_mode='human').\n",
    "    \"\"\"\n",
    "    # Create a new environment with graphical rendering\n",
    "    env = gym.make(\"FrozenLake-v1\", map_name=\"8x8\", is_slippery=True, render_mode='human')\n",
    "\n",
    "    for ep in range(episodes):\n",
    "        state, info = env.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        steps = 0\n",
    "\n",
    "        print(f\"\\n--- Episode {ep + 1} ---\")\n",
    "\n",
    "        while not done:\n",
    "            action = policy[state]\n",
    "            state, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            total_reward += reward\n",
    "            steps += 1\n",
    "\n",
    "            # # Add delay so you can visually follow each step\n",
    "            # time.sleep(delay)\n",
    "            \n",
    "            print(f\"\\n Episode {ep + 1}: Step {steps}\")\n",
    "\n",
    "            # the goal position in the 4x4 map can be calculated as follows: 3 * 4 + 3 = 15.\n",
    "            if reward:\n",
    "                print(\"You Won!!!\")\n",
    "                print(f\"Episode {ep + 1} ended with reward: {reward}\")\n",
    "            \n",
    "            #Check for Termination\n",
    "            if done:\n",
    "                print(\"GAME OVER --- Terminated!!!\")\n",
    "                print(f\"Episode {ep + 1} ended with reward: {reward}\")\n",
    "            \n",
    "\n",
    "        print(f\"Episode finished in {steps} steps with reward: {total_reward}\")\n",
    "\n",
    "\n",
    "\n",
    "    env.close()\n",
    "\n",
    "\n",
    "run_policy(env, optimal_policy, episodes=3, delay=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f14b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
