{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a540a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52f55057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and load a simulation environment\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0a1a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment: CartPole\n",
    "# Documentation Link: https://gymnasium.farama.org/environments/classic_control/cart_pole/\n",
    "#\n",
    "# Goal: Is to balance the pole on the cart by moving the cart left or right for a given episode\n",
    "#\n",
    "# Agent: Cart\n",
    "#\n",
    "# Actions: 0 ---- Left\n",
    "#          1 ---- Right\n",
    "#\n",
    "# State: [\"Cart Position\",\"Cart Velocity\",\"Pole Angle\",\"poleVelocity\"]\n",
    "#\n",
    "# Reward: 1 for every step taken such that the pole is balanced successfully.\n",
    "#\n",
    "# Termination Condition:\n",
    "# 1. Pole Angle is greater than +-12 DEGREE\n",
    "# 2. Cart Position is greater than +-2.4\n",
    "# 3. Episode length greater than 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04b8d90",
   "metadata": {},
   "source": [
    "# Running Multiple Episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a0310d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Policy Function\n",
    "\n",
    "import random\n",
    "\n",
    "def explorationPolicyFunction(currentState):\n",
    "    validActions = [0,1]\n",
    "    action = random.choice(validActions)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24649e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode Step 0 Given Action 1 I got reward 1.0 and next state [ 0.020978    0.20691854 -0.0333182  -0.32917795]\n",
      "Episode Step 1 Given Action 1 I got reward 1.0 and next state [ 0.02511637  0.40249857 -0.03990176 -0.6321789 ]\n",
      "Episode Step 2 Given Action 0 I got reward 1.0 and next state [ 0.03316634  0.20795535 -0.05254534 -0.35232437]\n",
      "Episode Step 3 Given Action 1 I got reward 1.0 and next state [ 0.03732545  0.40378362 -0.05959182 -0.66110253]\n",
      "Episode Step 4 Given Action 0 I got reward 1.0 and next state [ 0.04540112  0.20953928 -0.07281388 -0.38776287]\n",
      "Episode Step 5 Given Action 0 I got reward 1.0 and next state [ 0.0495919   0.01552237 -0.08056913 -0.11889703]\n",
      "Episode Step 6 Given Action 1 I got reward 1.0 and next state [ 0.04990235  0.21170071 -0.08294708 -0.43587166]\n",
      "Episode Step 7 Given Action 1 I got reward 1.0 and next state [ 0.05413637  0.4078929  -0.09166451 -0.7535066 ]\n",
      "Episode Step 8 Given Action 0 I got reward 1.0 and next state [ 0.06229422  0.21414627 -0.10673464 -0.49101844]\n",
      "Episode Step 9 Given Action 0 I got reward 1.0 and next state [ 0.06657715  0.02067906 -0.11655501 -0.2337895 ]\n",
      "Episode Step 10 Given Action 1 I got reward 1.0 and next state [ 0.06699073  0.21725675 -0.1212308  -0.5608451 ]\n",
      "Episode Step 11 Given Action 1 I got reward 1.0 and next state [ 0.07133587  0.41385287 -0.1324477  -0.88912946]\n",
      "Episode Step 12 Given Action 1 I got reward 1.0 and next state [ 0.07961293  0.6104994  -0.15023029 -1.2203417 ]\n",
      "Episode Step 13 Given Action 1 I got reward 1.0 and next state [ 0.09182291  0.8072037  -0.17463712 -1.5560766 ]\n",
      "Episode Step 14 Given Action 0 I got reward 1.0 and next state [ 0.10796698  0.6145508  -0.20575865 -1.3225754 ]\n",
      "Episode Step 15 Given Action 0 I got reward 1.0 and next state [ 0.120258    0.42253497 -0.23221016 -1.1006943 ]\n",
      "GAME OVER --- Terminated!!!\n",
      "Episode Step 0 Given Action 1 I got reward 1.0 and next state [ 0.03981965  0.2187167  -0.0132593  -0.29810077]\n",
      "Episode Step 1 Given Action 1 I got reward 1.0 and next state [ 0.04419398  0.41402513 -0.01922132 -0.5949358 ]\n",
      "Episode Step 2 Given Action 0 I got reward 1.0 and next state [ 0.05247448  0.2191774  -0.03112004 -0.3083689 ]\n",
      "Episode Step 3 Given Action 1 I got reward 1.0 and next state [ 0.05685803  0.4147286  -0.03728741 -0.61070156]\n",
      "Episode Step 4 Given Action 0 I got reward 1.0 and next state [ 0.0651526   0.22014715 -0.04950145 -0.32999218]\n",
      "Episode Step 5 Given Action 1 I got reward 1.0 and next state [ 0.06955554  0.41593754 -0.05610129 -0.6378655 ]\n",
      "Episode Step 6 Given Action 1 I got reward 1.0 and next state [ 0.0778743   0.61179507 -0.0688586  -0.9476747 ]\n",
      "Episode Step 7 Given Action 0 I got reward 1.0 and next state [ 0.0901102   0.41766447 -0.08781209 -0.6773973 ]\n",
      "Episode Step 8 Given Action 0 I got reward 1.0 and next state [ 0.09846348  0.22386523 -0.10136004 -0.4136021 ]\n",
      "Episode Step 9 Given Action 1 I got reward 1.0 and next state [ 0.10294079  0.42026687 -0.10963208 -0.7364414 ]\n",
      "Episode Step 10 Given Action 0 I got reward 1.0 and next state [ 0.11134613  0.22681619 -0.1243609  -0.48017475]\n",
      "Episode Step 11 Given Action 1 I got reward 1.0 and next state [ 0.11588245  0.42345405 -0.1339644  -0.8093215 ]\n",
      "Episode Step 12 Given Action 1 I got reward 1.0 and next state [ 0.12435153  0.62013227 -0.15015084 -1.1409634 ]\n",
      "Episode Step 13 Given Action 1 I got reward 1.0 and next state [ 0.13675418  0.8168633  -0.1729701  -1.4767183 ]\n",
      "Episode Step 14 Given Action 0 I got reward 1.0 and next state [ 0.15309145  0.6242242  -0.20250447 -1.2426715 ]\n",
      "Episode Step 15 Given Action 0 I got reward 1.0 and next state [ 0.16557592  0.43219304 -0.2273579  -1.019641  ]\n",
      "GAME OVER --- Terminated!!!\n",
      "Episode Step 0 Given Action 0 I got reward 1.0 and next state [ 0.04409537 -0.18568292 -0.01233164  0.3141511 ]\n",
      "Episode Step 1 Given Action 0 I got reward 1.0 and next state [ 0.04038171 -0.38062707 -0.00604862  0.6029197 ]\n",
      "Episode Step 2 Given Action 1 I got reward 1.0 and next state [ 0.03276917 -0.18542103  0.00600977  0.3083377 ]\n",
      "Episode Step 3 Given Action 0 I got reward 1.0 and next state [ 0.02906075 -0.3806281   0.01217653  0.60290986]\n",
      "Episode Step 4 Given Action 0 I got reward 1.0 and next state [ 0.02144819 -0.5759182   0.02423472  0.89940315]\n",
      "Episode Step 5 Given Action 0 I got reward 1.0 and next state [ 0.00992982 -0.7713601   0.04222279  1.1996042 ]\n",
      "Episode Step 6 Given Action 0 I got reward 1.0 and next state [-0.00549738 -0.9670021   0.06621487  1.5052154 ]\n",
      "Episode Step 7 Given Action 1 I got reward 1.0 and next state [-0.02483742 -0.7727429   0.09631918  1.2339182 ]\n",
      "Episode Step 8 Given Action 0 I got reward 1.0 and next state [-0.04029228 -0.9689621   0.12099754  1.5551567 ]\n",
      "Episode Step 9 Given Action 1 I got reward 1.0 and next state [-0.05967152 -0.77548     0.15210068  1.3025421 ]\n",
      "Episode Step 10 Given Action 1 I got reward 1.0 and next state [-0.07518112 -0.58257914  0.17815152  1.0610768 ]\n",
      "Episode Step 11 Given Action 0 I got reward 1.0 and next state [-0.0868327  -0.779555    0.19937305  1.4039642 ]\n",
      "Episode Step 12 Given Action 1 I got reward 1.0 and next state [-0.10242381 -0.5873879   0.22745234  1.1796516 ]\n",
      "GAME OVER --- Terminated!!!\n",
      "Episode Step 0 Given Action 1 I got reward 1.0 and next state [-0.00116242  0.151467    0.021348   -0.3321966 ]\n",
      "Episode Step 1 Given Action 1 I got reward 1.0 and next state [ 0.00186692  0.34627867  0.01470407 -0.6180717 ]\n",
      "Episode Step 2 Given Action 1 I got reward 1.0 and next state [ 0.00879249  0.5411922   0.00234264 -0.9060875 ]\n",
      "Episode Step 3 Given Action 1 I got reward 1.0 and next state [ 0.01961633  0.73628235 -0.01577911 -1.1980332 ]\n",
      "Episode Step 4 Given Action 1 I got reward 1.0 and next state [ 0.03434198  0.93160486 -0.03973978 -1.4956194 ]\n",
      "Episode Step 5 Given Action 0 I got reward 1.0 and next state [ 0.05297408  0.73698807 -0.06965216 -1.215605  ]\n",
      "Episode Step 6 Given Action 0 I got reward 1.0 and next state [ 0.06771384  0.5428302  -0.09396426 -0.9455357 ]\n",
      "Episode Step 7 Given Action 1 I got reward 1.0 and next state [ 0.07857045  0.73908365 -0.11287498 -1.266202  ]\n",
      "Episode Step 8 Given Action 1 I got reward 1.0 and next state [ 0.09335212  0.93545216 -0.13819902 -1.5919952 ]\n",
      "Episode Step 9 Given Action 1 I got reward 1.0 and next state [ 0.11206116  1.1319175  -0.17003892 -1.9243848 ]\n",
      "Episode Step 10 Given Action 0 I got reward 1.0 and next state [ 0.13469951  0.93898034 -0.20852663 -1.6889037 ]\n",
      "Episode Step 11 Given Action 0 I got reward 1.0 and next state [ 0.15347911  0.7467896  -0.2423047  -1.4677262 ]\n",
      "GAME OVER --- Terminated!!!\n",
      "Episode Step 0 Given Action 1 I got reward 1.0 and next state [ 0.0425075   0.19873783 -0.00892265 -0.2579127 ]\n",
      "Episode Step 1 Given Action 1 I got reward 1.0 and next state [ 0.04648225  0.39398602 -0.0140809  -0.5533965 ]\n",
      "Episode Step 2 Given Action 0 I got reward 1.0 and next state [ 0.05436197  0.19906461 -0.02514883 -0.26518306]\n",
      "Episode Step 3 Given Action 0 I got reward 1.0 and next state [ 0.05834327  0.00431046 -0.03045249  0.01946281]\n",
      "Episode Step 4 Given Action 1 I got reward 1.0 and next state [ 0.05842947  0.1998556  -0.03006324 -0.28267056]\n",
      "Episode Step 5 Given Action 0 I got reward 1.0 and next state [ 0.06242659  0.00517507 -0.03571665  0.00038103]\n",
      "Episode Step 6 Given Action 1 I got reward 1.0 and next state [ 0.06253009  0.20079057 -0.03570903 -0.30335355]\n",
      "Episode Step 7 Given Action 0 I got reward 1.0 and next state [ 0.0665459   0.00619524 -0.0417761  -0.02214285]\n",
      "Episode Step 8 Given Action 0 I got reward 1.0 and next state [ 0.06666981 -0.18830347 -0.04221895  0.25707206]\n",
      "Episode Step 9 Given Action 1 I got reward 1.0 and next state [ 0.06290373  0.00739501 -0.03707751 -0.04862276]\n",
      "Episode Step 10 Given Action 0 I got reward 1.0 and next state [ 0.06305163 -0.18717621 -0.03804997  0.23213518]\n",
      "Episode Step 11 Given Action 1 I got reward 1.0 and next state [ 0.05930811  0.00846819 -0.03340726 -0.072303  ]\n",
      "Episode Step 12 Given Action 1 I got reward 1.0 and next state [ 0.05947747  0.20405276 -0.03485332 -0.37533608]\n",
      "Episode Step 13 Given Action 0 I got reward 1.0 and next state [ 0.06355853  0.00944276 -0.04236005 -0.09384315]\n",
      "Episode Step 14 Given Action 0 I got reward 1.0 and next state [ 0.06374738 -0.18504725 -0.04423691  0.18518005]\n",
      "Episode Step 15 Given Action 0 I got reward 1.0 and next state [ 0.06004644 -0.37950927 -0.04053331  0.4635863 ]\n",
      "Episode Step 16 Given Action 0 I got reward 1.0 and next state [ 0.05245625 -0.5740357  -0.03126158  0.7432227 ]\n",
      "Episode Step 17 Given Action 1 I got reward 1.0 and next state [ 0.04097554 -0.3784965  -0.01639713  0.44086784]\n",
      "Episode Step 18 Given Action 0 I got reward 1.0 and next state [ 0.03340561 -0.5733826  -0.00757977  0.72833717]\n",
      "Episode Step 19 Given Action 1 I got reward 1.0 and next state [ 0.02193796 -0.3781567   0.00698697  0.4332783 ]\n",
      "Episode Step 20 Given Action 0 I got reward 1.0 and next state [ 0.01437482 -0.5733769   0.01565254  0.72815555]\n",
      "Episode Step 21 Given Action 1 I got reward 1.0 and next state [ 0.00290729 -0.37847477  0.03021565  0.44043985]\n",
      "Episode Step 22 Given Action 0 I got reward 1.0 and next state [-0.00466221 -0.574011    0.03902445  0.7424924 ]\n",
      "Episode Step 23 Given Action 1 I got reward 1.0 and next state [-0.01614243 -0.37944886  0.0538743   0.46234164]\n",
      "Episode Step 24 Given Action 1 I got reward 1.0 and next state [-0.02373141 -0.18512803  0.06312113  0.1871147 ]\n",
      "Episode Step 25 Given Action 0 I got reward 1.0 and next state [-0.02743397 -0.38109362  0.06686342  0.499023  ]\n",
      "Episode Step 26 Given Action 0 I got reward 1.0 and next state [-0.03505584 -0.5770914   0.07684388  0.8120059 ]\n",
      "Episode Step 27 Given Action 0 I got reward 1.0 and next state [-0.04659767 -0.77317715  0.093084    1.1278363 ]\n",
      "Episode Step 28 Given Action 1 I got reward 1.0 and next state [-0.06206121 -0.5793896   0.11564072  0.86574066]\n",
      "Episode Step 29 Given Action 1 I got reward 1.0 and next state [-0.073649   -0.38601536  0.13295554  0.61153924]\n",
      "Episode Step 30 Given Action 1 I got reward 1.0 and next state [-0.08136931 -0.19297764  0.14518632  0.36351207]\n",
      "Episode Step 31 Given Action 0 I got reward 1.0 and next state [-0.08522886 -0.3898325   0.15245657  0.69822264]\n",
      "Episode Step 32 Given Action 0 I got reward 1.0 and next state [-0.09302551 -0.5867027   0.16642101  1.0347515 ]\n",
      "Episode Step 33 Given Action 1 I got reward 1.0 and next state [-0.10475957 -0.39413726  0.18711604  0.7985963 ]\n",
      "Episode Step 34 Given Action 1 I got reward 1.0 and next state [-0.11264231 -0.20200737  0.20308797  0.5701237 ]\n",
      "Episode Step 35 Given Action 0 I got reward 1.0 and next state [-0.11668245 -0.3993112   0.21449044  0.9192953 ]\n",
      "GAME OVER --- Terminated!!!\n",
      "Episode Step 0 Given Action 1 I got reward 1.0 and next state [ 0.00136104  0.19127636  0.00429177 -0.30862758]\n",
      "Episode Step 1 Given Action 0 I got reward 1.0 and next state [ 0.00518657 -0.00390648 -0.00188078 -0.01459424]\n",
      "Episode Step 2 Given Action 0 I got reward 1.0 and next state [ 0.00510844 -0.1990014  -0.00217266  0.2774947 ]\n",
      "Episode Step 3 Given Action 0 I got reward 1.0 and next state [ 0.00112841 -0.3940923   0.00337723  0.56949157]\n",
      "Episode Step 4 Given Action 1 I got reward 1.0 and next state [-0.00675343 -0.19901787  0.01476706  0.2778745 ]\n",
      "Episode Step 5 Given Action 1 I got reward 1.0 and next state [-0.01073379 -0.00410967  0.02032455 -0.01011457]\n",
      "Episode Step 6 Given Action 1 I got reward 1.0 and next state [-0.01081598  0.190715    0.02012226 -0.2963162 ]\n",
      "Episode Step 7 Given Action 0 I got reward 1.0 and next state [-0.00700168 -0.00468795  0.01419594  0.00264443]\n",
      "Episode Step 8 Given Action 0 I got reward 1.0 and next state [-0.00709544 -0.20001058  0.01424883  0.29977232]\n",
      "Episode Step 9 Given Action 1 I got reward 1.0 and next state [-0.01109565 -0.0050946   0.02024427  0.01161704]\n",
      "Episode Step 10 Given Action 0 I got reward 1.0 and next state [-0.01119755 -0.20050094  0.02047661  0.3106179 ]\n",
      "Episode Step 11 Given Action 0 I got reward 1.0 and next state [-0.01520756 -0.39590856  0.02668897  0.60968757]\n",
      "Episode Step 12 Given Action 0 I got reward 1.0 and next state [-0.02312574 -0.59139323  0.03888272  0.9106558 ]\n",
      "Episode Step 13 Given Action 0 I got reward 1.0 and next state [-0.0349536  -0.78701913  0.05709584  1.2153015 ]\n",
      "Episode Step 14 Given Action 1 I got reward 1.0 and next state [-0.05069398 -0.59267837  0.08140187  0.9410424 ]\n",
      "Episode Step 15 Given Action 1 I got reward 1.0 and next state [-0.06254755 -0.39874223  0.10022271  0.6750072 ]\n",
      "Episode Step 16 Given Action 1 I got reward 1.0 and next state [-0.0705224  -0.20514536  0.11372286  0.41548532]\n",
      "Episode Step 17 Given Action 0 I got reward 1.0 and next state [-0.07462531 -0.40167993  0.12203257  0.7417454 ]\n",
      "Episode Step 18 Given Action 1 I got reward 1.0 and next state [-0.0826589  -0.20843498  0.13686748  0.48982224]\n",
      "Episode Step 19 Given Action 1 I got reward 1.0 and next state [-0.0868276  -0.01548238  0.14666392  0.24321353]\n",
      "Episode Step 20 Given Action 0 I got reward 1.0 and next state [-0.08713724 -0.21236159  0.1515282   0.5783266 ]\n",
      "Episode Step 21 Given Action 0 I got reward 1.0 and next state [-0.09138448 -0.40924606  0.16309473  0.91464835]\n",
      "Episode Step 22 Given Action 1 I got reward 1.0 and next state [-0.0995694  -0.21666086  0.1813877   0.67734164]\n",
      "Episode Step 23 Given Action 1 I got reward 1.0 and next state [-0.10390262 -0.0244605   0.19493452  0.4468069 ]\n",
      "Episode Step 24 Given Action 1 I got reward 1.0 and next state [-0.10439183  0.16744696  0.20387067  0.22134618]\n",
      "Episode Step 25 Given Action 1 I got reward 1.0 and next state [-0.10104289  0.35916013  0.20829758 -0.00074443]\n",
      "Episode Step 26 Given Action 0 I got reward 1.0 and next state [-0.09385969  0.16175424  0.2082827   0.34976143]\n",
      "Episode Step 27 Given Action 0 I got reward 1.0 and next state [-0.0906246  -0.03562694  0.21527793  0.7002277 ]\n",
      "GAME OVER --- Terminated!!!\n",
      "Episode Step 0 Given Action 1 I got reward 1.0 and next state [ 0.05041999  0.23910129  0.03087378 -0.31518388]\n",
      "Episode Step 1 Given Action 1 I got reward 1.0 and next state [ 0.05520201  0.43377018  0.02457011 -0.5979726 ]\n",
      "Episode Step 2 Given Action 1 I got reward 1.0 and next state [ 0.06387741  0.62853986  0.01261065 -0.8828161 ]\n",
      "Episode Step 3 Given Action 1 I got reward 1.0 and next state [ 0.07644821  0.8234883  -0.00504567 -1.1715081 ]\n",
      "Episode Step 4 Given Action 0 I got reward 1.0 and next state [ 0.09291798  0.62843233 -0.02847583 -0.8804112 ]\n",
      "Episode Step 5 Given Action 1 I got reward 1.0 and next state [ 0.10548662  0.8239293  -0.04608405 -1.1819085 ]\n",
      "Episode Step 6 Given Action 0 I got reward 1.0 and next state [ 0.12196521  0.62943476 -0.06972222 -0.90402037]\n",
      "Episode Step 7 Given Action 0 I got reward 1.0 and next state [ 0.13455391  0.43532285 -0.08780263 -0.6340417 ]\n",
      "Episode Step 8 Given Action 0 I got reward 1.0 and next state [ 0.14326036  0.24152832 -0.10048346 -0.3702505 ]\n",
      "Episode Step 9 Given Action 1 I got reward 1.0 and next state [ 0.14809093  0.43792364 -0.10788848 -0.69284993]\n",
      "Episode Step 10 Given Action 0 I got reward 1.0 and next state [ 0.1568494   0.2444507  -0.12174547 -0.4359856 ]\n",
      "Episode Step 11 Given Action 1 I got reward 1.0 and next state [ 0.16173841  0.44106674 -0.13046518 -0.76443154]\n",
      "Episode Step 12 Given Action 0 I got reward 1.0 and next state [ 0.17055975  0.24795967 -0.14575382 -0.51548064]\n",
      "Episode Step 13 Given Action 0 I got reward 1.0 and next state [ 0.17551894  0.0551585  -0.15606342 -0.27204543]\n",
      "Episode Step 14 Given Action 1 I got reward 1.0 and next state [ 0.17662211  0.25212306 -0.16150433 -0.6095983 ]\n",
      "Episode Step 15 Given Action 1 I got reward 1.0 and next state [ 0.18166457  0.44909018 -0.1736963  -0.94848025]\n",
      "Episode Step 16 Given Action 0 I got reward 1.0 and next state [ 0.19064638  0.25667834 -0.1926659  -0.7150157 ]\n",
      "Episode Step 17 Given Action 0 I got reward 1.0 and next state [ 0.19577995  0.0646712  -0.20696622 -0.48862797]\n",
      "Episode Step 18 Given Action 1 I got reward 1.0 and next state [ 0.19707337  0.2620197  -0.21673878 -0.8387478 ]\n",
      "GAME OVER --- Terminated!!!\n",
      "Episode Step 0 Given Action 1 I got reward 1.0 and next state [ 0.04391564  0.21351016  0.00330259 -0.33983105]\n",
      "Episode Step 1 Given Action 0 I got reward 1.0 and next state [ 0.04818585  0.01834137 -0.00349403 -0.04610851]\n",
      "Episode Step 2 Given Action 1 I got reward 1.0 and next state [ 0.04855268  0.21351326 -0.0044162  -0.3398918 ]\n",
      "Episode Step 3 Given Action 1 I got reward 1.0 and next state [ 0.05282294  0.40869775 -0.01121404 -0.63396406]\n",
      "Episode Step 4 Given Action 1 I got reward 1.0 and next state [ 0.0609969   0.60397434 -0.02389332 -0.93015736]\n",
      "Episode Step 5 Given Action 1 I got reward 1.0 and next state [ 0.07307638  0.79941046 -0.04249647 -1.2302519 ]\n",
      "Episode Step 6 Given Action 1 I got reward 1.0 and next state [ 0.08906459  0.9950526  -0.0671015  -1.5359403 ]\n",
      "Episode Step 7 Given Action 1 I got reward 1.0 and next state [ 0.10896564  1.1909152  -0.09782031 -1.8487861 ]\n",
      "Episode Step 8 Given Action 0 I got reward 1.0 and next state [ 0.13278395  0.9969969  -0.13479604 -1.5880126 ]\n",
      "Episode Step 9 Given Action 1 I got reward 1.0 and next state [ 0.1527239   1.1934385  -0.16655628 -1.919512  ]\n",
      "Episode Step 10 Given Action 1 I got reward 1.0 and next state [ 0.17659266  1.389914   -0.20494652 -2.2588885 ]\n",
      "Episode Step 11 Given Action 1 I got reward 1.0 and next state [ 0.20439094  1.5862854  -0.2501243  -2.6071143 ]\n",
      "GAME OVER --- Terminated!!!\n",
      "Episode Step 0 Given Action 1 I got reward 1.0 and next state [-0.0248264   0.15643755 -0.00494769 -0.33503127]\n",
      "Episode Step 1 Given Action 1 I got reward 1.0 and next state [-0.02169765  0.35162956 -0.01164832 -0.6292703 ]\n",
      "Episode Step 2 Given Action 0 I got reward 1.0 and next state [-0.01466506  0.15667209 -0.02423372 -0.34027848]\n",
      "Episode Step 3 Given Action 1 I got reward 1.0 and next state [-0.01153162  0.35213032 -0.03103929 -0.64050376]\n",
      "Episode Step 4 Given Action 0 I got reward 1.0 and next state [-0.00448901  0.15745452 -0.04384937 -0.3577548 ]\n",
      "Episode Step 5 Given Action 0 I got reward 1.0 and next state [-0.00133992 -0.0370175  -0.05100446 -0.07921475]\n",
      "Episode Step 6 Given Action 1 I got reward 1.0 and next state [-0.00208027  0.15879712 -0.05258876 -0.3875435 ]\n",
      "Episode Step 7 Given Action 1 I got reward 1.0 and next state [ 0.00109567  0.35462457 -0.06033963 -0.6963326 ]\n",
      "Episode Step 8 Given Action 1 I got reward 1.0 and next state [ 0.00818816  0.5505291  -0.07426628 -1.0073837 ]\n",
      "Episode Step 9 Given Action 0 I got reward 1.0 and next state [ 0.01919875  0.35647306 -0.09441395 -0.7389162 ]\n",
      "Episode Step 10 Given Action 1 I got reward 1.0 and next state [ 0.02632821  0.55276316 -0.10919227 -1.0597565 ]\n",
      "Episode Step 11 Given Action 1 I got reward 1.0 and next state [ 0.03738347  0.7491486  -0.13038741 -1.3846191 ]\n",
      "Episode Step 12 Given Action 0 I got reward 1.0 and next state [ 0.05236644  0.55587137 -0.15807979 -1.1353896 ]\n",
      "Episode Step 13 Given Action 0 I got reward 1.0 and next state [ 0.06348387  0.36313045 -0.18078758 -0.8961651 ]\n",
      "Episode Step 14 Given Action 1 I got reward 1.0 and next state [ 0.07074648  0.56018203 -0.19871089 -1.2397877 ]\n",
      "Episode Step 15 Given Action 0 I got reward 1.0 and next state [ 0.08195012  0.36808714 -0.22350663 -1.0153528 ]\n",
      "GAME OVER --- Terminated!!!\n",
      "Episode Step 0 Given Action 1 I got reward 1.0 and next state [-0.04561395  0.21736352  0.04928387 -0.29766238]\n",
      "Episode Step 1 Given Action 1 I got reward 1.0 and next state [-0.04126668  0.41174954  0.04333062 -0.5744038 ]\n",
      "Episode Step 2 Given Action 0 I got reward 1.0 and next state [-0.03303169  0.21604776  0.03184254 -0.26839146]\n",
      "Episode Step 3 Given Action 1 I got reward 1.0 and next state [-0.02871073  0.41070116  0.02647471 -0.5508634 ]\n",
      "Episode Step 4 Given Action 0 I got reward 1.0 and next state [-0.02049671  0.21521756  0.01545745 -0.2499581 ]\n",
      "Episode Step 5 Given Action 0 I got reward 1.0 and next state [-0.01619236  0.01987832  0.01045828  0.04756007]\n",
      "Episode Step 6 Given Action 0 I got reward 1.0 and next state [-0.01579479 -0.17539202  0.01140949  0.34352425]\n",
      "Episode Step 7 Given Action 1 I got reward 1.0 and next state [-0.01930263  0.01956577  0.01827997  0.05446091]\n",
      "Episode Step 8 Given Action 0 I got reward 1.0 and next state [-0.01891132 -0.17581345  0.01936919  0.3528548 ]\n",
      "Episode Step 9 Given Action 0 I got reward 1.0 and next state [-0.02242758 -0.3712054   0.02642628  0.65158194]\n",
      "Episode Step 10 Given Action 0 I got reward 1.0 and next state [-0.02985169 -0.56668526  0.03945792  0.95246774]\n",
      "Episode Step 11 Given Action 1 I got reward 1.0 and next state [-0.0411854  -0.37211582  0.05850728  0.6724384 ]\n",
      "Episode Step 12 Given Action 0 I got reward 1.0 and next state [-0.04862771 -0.56800014  0.07195605  0.9829534 ]\n",
      "Episode Step 13 Given Action 1 I got reward 1.0 and next state [-0.05998772 -0.37391222  0.09161511  0.71371174]\n",
      "Episode Step 14 Given Action 0 I got reward 1.0 and next state [-0.06746596 -0.57017505  0.10588935  1.0337685 ]\n",
      "Episode Step 15 Given Action 0 I got reward 1.0 and next state [-0.07886946 -0.7665336   0.12656473  1.35773   ]\n",
      "Episode Step 16 Given Action 0 I got reward 1.0 and next state [-0.09420013 -0.9629953   0.15371932  1.6871761 ]\n",
      "Episode Step 17 Given Action 0 I got reward 1.0 and next state [-0.11346004 -1.1595249   0.18746284  2.0235102 ]\n",
      "Episode Step 18 Given Action 0 I got reward 1.0 and next state [-0.13665053 -1.3560289   0.22793305  2.367894  ]\n",
      "GAME OVER --- Terminated!!!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "\n",
    "for episodeCount in range(1,11):\n",
    "    #initialize the state\n",
    "    env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "    observation,info = env.reset()\n",
    "\n",
    "    for episodeStep in range(400):\n",
    "        #Choose a random action\n",
    "        action = explorationPolicyFunction(observation)\n",
    "\n",
    "        #Supply action to the env\n",
    "        newState,reward,isTerminated,isTruncated,info = env.step(action)\n",
    "\n",
    "        #Add small delay and call render to see game in execution\n",
    "        time.sleep(0.02) #20ms delay\n",
    "        env.render()\n",
    "\n",
    "        #Print info\n",
    "        print(f\"Episode Step {episodeStep} Given Action {action} I got reward {reward} and next state {newState}\")\n",
    "\n",
    "        #Check for Termination\n",
    "        if isTerminated:\n",
    "            print(\"GAME OVER --- Terminated!!!\")\n",
    "            env.close()\n",
    "            break\n",
    "\n",
    "    #Check for Truncation(Episode ended)\n",
    "    if isTruncated:\n",
    "        (\"Episode Over. Total Allowed Steps Done. Agent was able to balance pole successfully :)\")\n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eba9df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
