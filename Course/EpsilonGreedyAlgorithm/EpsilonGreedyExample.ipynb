{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e4a0f36",
   "metadata": {},
   "source": [
    "# Exploration-Exploitation Dilemma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c2eef5",
   "metadata": {},
   "source": [
    "This is all about taking a decision on whether to choose Exploration or Exploitation as a method  to (to select an action) train a model.\n",
    "\n",
    "To deal with this dilemma, RL practitioners created multiple method:\n",
    "\n",
    "1. UCB (Upper Confidence Bound)\n",
    "2. Thompson Sampling\n",
    "3. Epsilon Greedy Algorithm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dbe01a",
   "metadata": {},
   "source": [
    "## Epsilon Greedy Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46UBWyIHtwkV",
   "metadata": {
    "id": "46UBWyIHtwkV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#Policy Function\n",
    "def epsilonGreedy(currentState,epsilon):\n",
    "    listActions=[0,1]\n",
    "    poleAngle=currentState\n",
    "\n",
    "    p = np.random.randn()\n",
    "\n",
    "    if p < epsilon:\n",
    "        #Exploration Strategy\n",
    "        action = random.choice(listActions)\n",
    "\n",
    "    else:\n",
    "        #Exploitation Strategy\n",
    "        if poleAngle < 0:\n",
    "            action = 0\n",
    "        else:\n",
    "            action = 1\n",
    "\n",
    "    return action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "770c74be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a0a1a80",
   "metadata": {
    "id": "2a0a1a80"
   },
   "outputs": [],
   "source": [
    "# Environment: CartPole\n",
    "# Documentation Link: https://gymnasium.farama.org/environments/classic_control/cart_pole/\n",
    "#\n",
    "# Goal: Is to balance the pole on the cart by moving the cart left or right for a given episode\n",
    "#\n",
    "# Agent: Cart\n",
    "#\n",
    "# Actions: 0 ---- Left\n",
    "#          1 ---- Right\n",
    "#\n",
    "# State: [\"Cart Position\",\"Cart Velocity\",\"Pole Angle\",\"poleVelocity\"]\n",
    "#\n",
    "# Reward: 1 for every step taken such that the pole is balanced successfully.\n",
    "#\n",
    "# Termination Condition:\n",
    "# 1. Pole Angle is greater than +-12 DEGREE\n",
    "# 2. Cart Position is greater than +-2.4\n",
    "# 3. Episode length greater than 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24649e91",
   "metadata": {
    "id": "24649e91",
    "outputId": "d535ca53-62d5-4cf2-eacb-e392f89d25ba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oysterable/delete/ReinforcementLearning/rlvenv/lib/python3.12/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode Step 0 Given Action 1 I got reward 1.0 and next state [ 0.03553887  0.16738862  0.01286034 -0.24731459]\n",
      "Episode Step 1 Given Action 0 I got reward 1.0 and next state [ 0.03888664 -0.02791462  0.00791404  0.04939688]\n",
      "Episode Step 2 Given Action 1 I got reward 1.0 and next state [ 0.03832835  0.16709296  0.00890198 -0.24077863]\n",
      "Episode Step 3 Given Action 1 I got reward 1.0 and next state [ 0.04167021  0.36208662  0.00408641 -0.53064036]\n",
      "Episode Step 4 Given Action 1 I got reward 1.0 and next state [ 0.04891194  0.55715084 -0.0065264  -0.82203287]\n",
      "Episode Step 5 Given Action 1 I got reward 1.0 and next state [ 0.06005496  0.7523615  -0.02296706 -1.1167613 ]\n",
      "Episode Step 6 Given Action 1 I got reward 1.0 and next state [ 0.07510219  0.9477772  -0.04530228 -1.4165593 ]\n",
      "Episode Step 7 Given Action 0 I got reward 1.0 and next state [ 0.09405773  0.75324464 -0.07363347 -1.1383742 ]\n",
      "Episode Step 8 Given Action 1 I got reward 1.0 and next state [ 0.10912263  0.94924814 -0.09640095 -1.4532114 ]\n",
      "Episode Step 9 Given Action 0 I got reward 1.0 and next state [ 0.12810759  0.75543326 -0.12546518 -1.1921369 ]\n",
      "Episode Step 10 Given Action 1 I got reward 1.0 and next state [ 0.14321625  0.9519371  -0.14930792 -1.5213659 ]\n",
      "Episode Step 11 Given Action 0 I got reward 1.0 and next state [ 0.16225499  0.75890136 -0.17973524 -1.2787673 ]\n",
      "Episode Step 12 Given Action 1 I got reward 1.0 and next state [ 0.17743301  0.9558002  -0.20531058 -1.6219159 ]\n",
      "Episode Step 13 Given Action 1 I got reward 1.0 and next state [ 0.19654903  1.1526626  -0.2377489  -1.970946  ]\n",
      "GAME OVER --- Terminated!!!\n",
      "Episode Step 0 Given Action 1 I got reward 1.0 and next state [-1.8653562e-04  1.8137005e-01  1.1033865e-02 -2.7849004e-01]\n",
      "Episode Step 1 Given Action 0 I got reward 1.0 and next state [ 0.00344087 -0.01390756  0.00546406  0.01765243]\n",
      "Episode Step 2 Given Action 0 I got reward 1.0 and next state [ 0.00316271 -0.20910744  0.00581711  0.3120543 ]\n",
      "Episode Step 3 Given Action 0 I got reward 1.0 and next state [-0.00101943 -0.40431178  0.0120582   0.6065661 ]\n",
      "Episode Step 4 Given Action 0 I got reward 1.0 and next state [-0.00910567 -0.59960026  0.02418952  0.9030225 ]\n",
      "Episode Step 5 Given Action 0 I got reward 1.0 and next state [-0.02109767 -0.7950414   0.04224997  1.2032094 ]\n",
      "Episode Step 6 Given Action 0 I got reward 1.0 and next state [-0.0369985  -0.9906833   0.06631416  1.5088283 ]\n",
      "Episode Step 7 Given Action 1 I got reward 1.0 and next state [-0.05681217 -0.79642487  0.09649073  1.2375631 ]\n",
      "Episode Step 8 Given Action 1 I got reward 1.0 and next state [-0.07274067 -0.6026658   0.12124199  0.97660077]\n",
      "Episode Step 9 Given Action 0 I got reward 1.0 and next state [-0.08479398 -0.79918665  0.14077401  1.3047761 ]\n",
      "Episode Step 10 Given Action 1 I got reward 1.0 and next state [-0.10077772 -0.60610217  0.16686952  1.0592653 ]\n",
      "Episode Step 11 Given Action 1 I got reward 1.0 and next state [-0.11289976 -0.41353607  0.18805483  0.8232607 ]\n",
      "Episode Step 12 Given Action 1 I got reward 1.0 and next state [-0.12117048 -0.22141565  0.20452005  0.5951236 ]\n",
      "Episode Step 13 Given Action 1 I got reward 1.0 and next state [-0.12559879 -0.02965431  0.21642251  0.37318704]\n",
      "GAME OVER --- Terminated!!!\n",
      "Episode Step 0 Given Action 0 I got reward 1.0 and next state [ 0.02633417 -0.16603501 -0.04355116  0.2837487 ]\n",
      "Episode Step 1 Given Action 0 I got reward 1.0 and next state [ 0.02301347 -0.3605096  -0.03787618  0.562384  ]\n",
      "Episode Step 2 Given Action 0 I got reward 1.0 and next state [ 0.01580327 -0.5550802  -0.0266285   0.84289753]\n",
      "Episode Step 3 Given Action 0 I got reward 1.0 and next state [ 0.00470167 -0.74982876 -0.00977055  1.127089  ]\n",
      "Episode Step 4 Given Action 0 I got reward 1.0 and next state [-0.0102949  -0.94482136  0.01277123  1.4166914 ]\n",
      "Episode Step 5 Given Action 0 I got reward 1.0 and next state [-0.02919133 -1.140099    0.04110505  1.7133389 ]\n",
      "Episode Step 6 Given Action 0 I got reward 1.0 and next state [-0.05199331 -1.3356681   0.07537183  2.0185258 ]\n",
      "Episode Step 7 Given Action 1 I got reward 1.0 and next state [-0.07870667 -1.1414042   0.11574235  1.7500958 ]\n",
      "Episode Step 8 Given Action 0 I got reward 1.0 and next state [-0.10153475 -1.3376347   0.15074426  2.0764246 ]\n",
      "Episode Step 9 Given Action 0 I got reward 1.0 and next state [-0.12828745 -1.5339303   0.19227275  2.41168   ]\n",
      "Episode Step 10 Given Action 0 I got reward 1.0 and next state [-0.15896606 -1.7301338   0.24050635  2.7567425 ]\n",
      "GAME OVER --- Terminated!!!\n",
      "Episode Step 0 Given Action 0 I got reward 1.0 and next state [-0.022      -0.19885102 -0.04562391  0.28928542]\n",
      "Episode Step 1 Given Action 1 I got reward 1.0 and next state [-0.02597702 -0.00310918 -0.03983819 -0.01743057]\n",
      "Episode Step 2 Given Action 0 I got reward 1.0 and next state [-0.0260392  -0.19763783 -0.04018681  0.26242155]\n",
      "Episode Step 3 Given Action 1 I got reward 1.0 and next state [-0.02999196 -0.00196597 -0.03493838 -0.04266101]\n",
      "Episode Step 4 Given Action 0 I got reward 1.0 and next state [-0.03003128 -0.19656995 -0.0357916   0.23879702]\n",
      "Episode Step 5 Given Action 0 I got reward 1.0 and next state [-0.03396268 -0.39116278 -0.03101566  0.5199789 ]\n",
      "Episode Step 6 Given Action 0 I got reward 1.0 and next state [-0.04178593 -0.5858347  -0.02061608  0.8027291 ]\n",
      "Episode Step 7 Given Action 0 I got reward 1.0 and next state [-0.05350263 -0.78066796 -0.0045615   1.0888562 ]\n",
      "Episode Step 8 Given Action 1 I got reward 1.0 and next state [-0.06911599 -0.5854862   0.01721563  0.7947455 ]\n",
      "Episode Step 9 Given Action 1 I got reward 1.0 and next state [-0.08082571 -0.39060467  0.03311054  0.50752777]\n",
      "Episode Step 10 Given Action 0 I got reward 1.0 and next state [-0.08863781 -0.5861772   0.0432611   0.81045836]\n",
      "Episode Step 11 Given Action 0 I got reward 1.0 and next state [-0.10036135 -0.7818642   0.05947026  1.1164292 ]\n",
      "Episode Step 12 Given Action 0 I got reward 1.0 and next state [-0.11599863 -0.9777142   0.08179884  1.4271587 ]\n",
      "Episode Step 13 Given Action 0 I got reward 1.0 and next state [-0.13555291 -1.1737459   0.11034202  1.7442452 ]\n",
      "Episode Step 14 Given Action 1 I got reward 1.0 and next state [-0.15902783 -0.98003864  0.14522693  1.487826  ]\n",
      "Episode Step 15 Given Action 1 I got reward 1.0 and next state [-0.17862861 -0.7869536   0.17498344  1.2437942 ]\n",
      "Episode Step 16 Given Action 1 I got reward 1.0 and next state [-0.19436768 -0.5944544   0.19985934  1.0106378 ]\n",
      "Episode Step 17 Given Action 1 I got reward 1.0 and next state [-0.20625676 -0.40247887  0.22007209  0.7867747 ]\n",
      "GAME OVER --- Terminated!!!\n",
      "Episode Step 0 Given Action 1 I got reward 1.0 and next state [-0.02381035  0.18503715  0.04939638 -0.25731513]\n",
      "Episode Step 1 Given Action 1 I got reward 1.0 and next state [-0.0201096   0.37942034  0.04425007 -0.5340177 ]\n",
      "Episode Step 2 Given Action 1 I got reward 1.0 and next state [-0.0125212   0.573893    0.03356972 -0.8124358 ]\n",
      "Episode Step 3 Given Action 1 I got reward 1.0 and next state [-1.0433353e-03  7.6853943e-01  1.7321007e-02 -1.0943733e+00]\n",
      "Episode Step 4 Given Action 0 I got reward 1.0 and next state [ 0.01432745  0.57319367 -0.00456646 -0.7963065 ]\n",
      "Episode Step 5 Given Action 1 I got reward 1.0 and next state [ 0.02579133  0.76837796 -0.02049259 -1.0904224 ]\n",
      "Episode Step 6 Given Action 0 I got reward 1.0 and next state [ 0.04115888  0.57353204 -0.04230104 -0.8042393 ]\n",
      "Episode Step 7 Given Action 1 I got reward 1.0 and next state [ 0.05262953  0.76920766 -0.05838582 -1.1099229 ]\n",
      "Episode Step 8 Given Action 1 I got reward 1.0 and next state [ 0.06801368  0.9650461  -0.08058428 -1.4203358 ]\n",
      "Episode Step 9 Given Action 1 I got reward 1.0 and next state [ 0.0873146  1.1610674 -0.108991  -1.7370796]\n",
      "Episode Step 10 Given Action 0 I got reward 1.0 and next state [ 0.11053595  0.9673437  -0.14373259 -1.4801983 ]\n",
      "Episode Step 11 Given Action 1 I got reward 1.0 and next state [ 0.12988283  1.1638974  -0.17333655 -1.8141007 ]\n",
      "Episode Step 12 Given Action 0 I got reward 1.0 and next state [ 0.15316077  0.9710778  -0.20961857 -1.5799116 ]\n",
      "GAME OVER --- Terminated!!!\n",
      "Episode Step 0 Given Action 1 I got reward 1.0 and next state [ 0.03294724  0.19887735 -0.00719036 -0.24558592]\n",
      "Episode Step 1 Given Action 0 I got reward 1.0 and next state [ 0.03692479  0.00385882 -0.01210208  0.04482035]\n",
      "Episode Step 2 Given Action 1 I got reward 1.0 and next state [ 0.03700196  0.1991522  -0.01120567 -0.2516562 ]\n",
      "Episode Step 3 Given Action 0 I got reward 1.0 and next state [ 0.04098501  0.00419204 -0.0162388   0.03747129]\n",
      "Episode Step 4 Given Action 0 I got reward 1.0 and next state [ 0.04106885 -0.19069332 -0.01548937  0.3249868 ]\n",
      "Episode Step 5 Given Action 0 I got reward 1.0 and next state [ 0.03725498 -0.38559136 -0.00898963  0.61274505]\n",
      "Episode Step 6 Given Action 0 I got reward 1.0 and next state [ 0.02954315 -0.5805865   0.00326527  0.90258306]\n",
      "Episode Step 7 Given Action 0 I got reward 1.0 and next state [ 0.01793142 -0.77575254  0.02131693  1.1962906 ]\n",
      "Episode Step 8 Given Action 0 I got reward 1.0 and next state [ 0.00241637 -0.97114384  0.04524274  1.4955777 ]\n",
      "Episode Step 9 Given Action 0 I got reward 1.0 and next state [-0.01700651 -1.1667858   0.0751543   1.8020371 ]\n",
      "Episode Step 10 Given Action 0 I got reward 1.0 and next state [-0.04034222 -1.3626628   0.11119504  2.1170979 ]\n",
      "Episode Step 11 Given Action 0 I got reward 1.0 and next state [-0.06759547 -1.5587045   0.15353699  2.4419682 ]\n",
      "Episode Step 12 Given Action 1 I got reward 1.0 and next state [-0.09876957 -1.3651915   0.20237637  2.200076  ]\n",
      "Episode Step 13 Given Action 0 I got reward 1.0 and next state [-0.1260734  -1.5616075   0.24637789  2.5477808 ]\n",
      "GAME OVER --- Terminated!!!\n",
      "Episode Step 0 Given Action 1 I got reward 1.0 and next state [ 0.00506476  0.2195783   0.04303061 -0.2589484 ]\n",
      "Episode Step 1 Given Action 1 I got reward 1.0 and next state [ 0.00945633  0.41406035  0.03785164 -0.53775436]\n",
      "Episode Step 2 Given Action 1 I got reward 1.0 and next state [ 0.01773753  0.6086303   0.02709655 -0.81827444]\n",
      "Episode Step 3 Given Action 1 I got reward 1.0 and next state [ 0.02991014  0.8033711   0.01073107 -1.1023129 ]\n",
      "Episode Step 4 Given Action 1 I got reward 1.0 and next state [ 0.04597756  0.9983502  -0.01131519 -1.39161   ]\n",
      "Episode Step 5 Given Action 1 I got reward 1.0 and next state [ 0.06594457  1.1936111  -0.0391474  -1.6878093 ]\n",
      "Episode Step 6 Given Action 0 I got reward 1.0 and next state [ 0.08981679  0.9989631  -0.07290358 -1.4075674 ]\n",
      "Episode Step 7 Given Action 0 I got reward 1.0 and next state [ 0.10979605  0.8048176  -0.10105493 -1.1385373 ]\n",
      "Episode Step 8 Given Action 1 I got reward 1.0 and next state [ 0.1258924   1.0011052  -0.12382568 -1.4611262 ]\n",
      "Episode Step 9 Given Action 0 I got reward 1.0 and next state [ 0.14591451  0.8076997  -0.1530482  -1.2095509 ]\n",
      "Episode Step 10 Given Action 1 I got reward 1.0 and next state [ 0.1620685   1.0044303  -0.17723921 -1.5460181 ]\n",
      "Episode Step 11 Given Action 1 I got reward 1.0 and next state [ 0.18215711  1.2011825  -0.20815958 -1.8883591 ]\n",
      "Episode Step 12 Given Action 1 I got reward 1.0 and next state [ 0.20618075  1.3978707  -0.24592675 -2.2377803 ]\n",
      "GAME OVER --- Terminated!!!\n",
      "Episode Step 0 Given Action 1 I got reward 1.0 and next state [-0.02128396  0.18419443 -0.01247334 -0.2771781 ]\n",
      "Episode Step 1 Given Action 0 I got reward 1.0 and next state [-0.01760008 -0.01074737 -0.01801691  0.01154476]\n",
      "Episode Step 2 Given Action 0 I got reward 1.0 and next state [-0.01781502 -0.20560636 -0.01778601  0.29848912]\n",
      "Episode Step 3 Given Action 0 I got reward 1.0 and next state [-0.02192715 -0.40047032 -0.01181623  0.58551   ]\n",
      "Episode Step 4 Given Action 0 I got reward 1.0 and next state [-2.9936556e-02 -5.9542477e-01 -1.0602847e-04  8.7444741e-01]\n",
      "Episode Step 5 Given Action 0 I got reward 1.0 and next state [-0.04184505 -0.7905453   0.01738292  1.167097  ]\n",
      "Episode Step 6 Given Action 0 I got reward 1.0 and next state [-0.05765596 -0.9858891   0.04072486  1.4651787 ]\n",
      "Episode Step 7 Given Action 0 I got reward 1.0 and next state [-0.07737374 -1.1814854   0.07002843  1.7702998 ]\n",
      "Episode Step 8 Given Action 0 I got reward 1.0 and next state [-0.10100345 -1.3773243   0.10543443  2.0839097 ]\n",
      "Episode Step 9 Given Action 0 I got reward 1.0 and next state [-0.12854993 -1.5733424   0.14711262  2.4072444 ]\n",
      "Episode Step 10 Given Action 0 I got reward 1.0 and next state [-0.16001679 -1.7694069   0.19525751  2.7412598 ]\n",
      "Episode Step 11 Given Action 1 I got reward 1.0 and next state [-0.19540492 -1.5761247   0.2500827   2.5138872 ]\n",
      "GAME OVER --- Terminated!!!\n",
      "Episode Step 0 Given Action 1 I got reward 1.0 and next state [ 0.01378569  0.22843708  0.01371958 -0.28623152]\n",
      "Episode Step 1 Given Action 1 I got reward 1.0 and next state [ 0.01835443  0.4233607   0.00799495 -0.574556  ]\n",
      "Episode Step 2 Given Action 1 I got reward 1.0 and next state [ 0.02682164  0.61836964 -0.00349617 -0.8647096 ]\n",
      "Episode Step 3 Given Action 1 I got reward 1.0 and next state [ 0.03918904  0.813539   -0.02079037 -1.1584897 ]\n",
      "Episode Step 4 Given Action 1 I got reward 1.0 and next state [ 0.05545982  1.0089257  -0.04396016 -1.4576182 ]\n",
      "Episode Step 5 Given Action 1 I got reward 1.0 and next state [ 0.07563833  1.2045585  -0.07311253 -1.7637042 ]\n",
      "Episode Step 6 Given Action 1 I got reward 1.0 and next state [ 0.0997295   1.4004271  -0.10838661 -2.0781982 ]\n",
      "Episode Step 7 Given Action 1 I got reward 1.0 and next state [ 0.12773804  1.5964677  -0.14995058 -2.4023368 ]\n",
      "Episode Step 8 Given Action 1 I got reward 1.0 and next state [ 0.1596674  1.7925467 -0.1979973 -2.7370753]\n",
      "Episode Step 9 Given Action 1 I got reward 1.0 and next state [ 0.19551833  1.9884423  -0.2527388  -3.0830092 ]\n",
      "GAME OVER --- Terminated!!!\n",
      "Episode Step 0 Given Action 0 I got reward 1.0 and next state [ 0.02636261 -0.16907848 -0.004597    0.26197684]\n",
      "Episode Step 1 Given Action 0 I got reward 1.0 and next state [ 0.02298104 -0.36413452  0.00064253  0.55320626]\n",
      "Episode Step 2 Given Action 0 I got reward 1.0 and next state [ 0.01569835 -0.5592655   0.01170666  0.84609157]\n",
      "Episode Step 3 Given Action 1 I got reward 1.0 and next state [ 0.00451304 -0.3643052   0.02862849  0.5571129 ]\n",
      "Episode Step 4 Given Action 0 I got reward 1.0 and next state [-0.00277307 -0.5598171   0.03977075  0.8586762 ]\n",
      "Episode Step 5 Given Action 0 I got reward 1.0 and next state [-0.01396941 -0.7554576   0.05694427  1.1635944 ]\n",
      "Episode Step 6 Given Action 0 I got reward 1.0 and next state [-0.02907856 -0.95127285  0.08021616  1.4735737 ]\n",
      "Episode Step 7 Given Action 1 I got reward 1.0 and next state [-0.04810402 -0.7572178   0.10968763  1.2069855 ]\n",
      "Episode Step 8 Given Action 0 I got reward 1.0 and next state [-0.06324837 -0.9535725   0.13382734  1.531931  ]\n",
      "Episode Step 9 Given Action 0 I got reward 1.0 and next state [-0.08231983 -1.1500295   0.16446596  1.8632094 ]\n",
      "Episode Step 10 Given Action 1 I got reward 1.0 and next state [-0.10532042 -0.95704794  0.20173015  1.6257786 ]\n",
      "Episode Step 11 Given Action 0 I got reward 1.0 and next state [-0.12446137 -1.1538903   0.23424572  1.9739617 ]\n",
      "GAME OVER --- Terminated!!!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "EPSILON = 0.2\n",
    "\n",
    "for episodeCount in range(1,11):\n",
    "    #initialize the state\n",
    "    env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "    \n",
    "    observation,info = env.reset()    \n",
    "    # observation (State): [\"Cart Position\",\"Cart Velocity\",\"Pole Angle\",\"poleVelocity\"]\n",
    "\n",
    "    \n",
    "\n",
    "    for episodeStep in range(400):\n",
    "        \n",
    "        #Choose a random action\n",
    "        state = observation[2] #Pole Angle\n",
    "        action = epsilonGreedy(state, EPSILON)\n",
    "\n",
    "        #Supply action to the env\n",
    "        newState,reward,isTerminated,isTruncated,info = env.step(action)\n",
    "\n",
    "        #Add small delay and call render to see game in execution\n",
    "        time.sleep(0.02) #20ms delay\n",
    "        env.render()\n",
    "\n",
    "        #Print info\n",
    "        print(f\"Episode Step {episodeStep} Given Action {action} I got reward {reward} and next state {newState}\")\n",
    "\n",
    "        #Check for Termination\n",
    "        if isTerminated:\n",
    "            print(\"GAME OVER --- Terminated!!!\")\n",
    "            env.close()\n",
    "            break\n",
    "\n",
    "    #Check for Truncation(Episode ended)\n",
    "    if isTruncated:\n",
    "        (\"Episode Over. Total Allowed Steps Done. Agent was able to balance pole successfully :)\")\n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eba9df",
   "metadata": {
    "id": "65eba9df"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
